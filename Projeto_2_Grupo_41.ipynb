{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "4b877ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpMax_L</th>\n",
       "      <th>J_Dz(e)</th>\n",
       "      <th>nHM</th>\n",
       "      <th>F01</th>\n",
       "      <th>F04</th>\n",
       "      <th>NssssC</th>\n",
       "      <th>nCb</th>\n",
       "      <th>C</th>\n",
       "      <th>nCp</th>\n",
       "      <th>nO</th>\n",
       "      <th>...</th>\n",
       "      <th>C_026</th>\n",
       "      <th>F02_CN</th>\n",
       "      <th>nHDon</th>\n",
       "      <th>SpMax_B</th>\n",
       "      <th>Psi_i_A</th>\n",
       "      <th>nN</th>\n",
       "      <th>SM6_B</th>\n",
       "      <th>nArCOOR</th>\n",
       "      <th>nX</th>\n",
       "      <th>Biodegradable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.919000</td>\n",
       "      <td>2.690900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.400000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.949000</td>\n",
       "      <td>1.591000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.253000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.170000</td>\n",
       "      <td>2.114400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.315000</td>\n",
       "      <td>1.967000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.257000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.932000</td>\n",
       "      <td>3.251200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.700000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.417000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.601000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.709800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.690000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.236000</td>\n",
       "      <td>3.394400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.400000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.351000</td>\n",
       "      <td>2.405000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.003000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4559</th>\n",
       "      <td>4.175650</td>\n",
       "      <td>3.454649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.398382</td>\n",
       "      <td>3.241090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.406748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4560</th>\n",
       "      <td>3.853731</td>\n",
       "      <td>2.747142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.429148</td>\n",
       "      <td>2.719309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.511511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4561</th>\n",
       "      <td>4.294771</td>\n",
       "      <td>3.471226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.422154</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.351666</td>\n",
       "      <td>2.729456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.699324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4562</th>\n",
       "      <td>4.560376</td>\n",
       "      <td>3.896390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.059198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.908802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4563</th>\n",
       "      <td>4.045097</td>\n",
       "      <td>2.847185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.386643</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.032224</td>\n",
       "      <td>2.613357</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.863314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4564 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SpMax_L   J_Dz(e)  nHM  F01  F04  NssssC  nCb          C  nCp   nO   \n",
       "0     3.919000  2.690900  0.0  0.0  0.0     0.0  0.0  31.400000  2.0  0.0  \\\n",
       "1     4.170000  2.114400  0.0  0.0  0.0     0.0  0.0  30.800000  1.0  1.0   \n",
       "2     3.932000  3.251200  0.0  0.0  0.0     0.0  0.0  26.700000  2.0  4.0   \n",
       "3     3.000000  2.709800  0.0  0.0  0.0     0.0  0.0  20.000000  NaN  2.0   \n",
       "4     4.236000  3.394400  0.0  0.0  0.0     0.0  0.0  29.400000  2.0  4.0   \n",
       "...        ...       ...  ...  ...  ...     ...  ...        ...  ...  ...   \n",
       "4559  4.175650  3.454649  0.0  0.0  0.0     0.0  0.0  27.300000  2.0  2.0   \n",
       "4560  3.853731  2.747142  0.0  NaN  0.0     0.0  0.0  33.300000  0.0  0.0   \n",
       "4561  4.294771  3.471226  0.0  0.0  0.0     0.0  0.0  28.422154  2.0  2.0   \n",
       "4562  4.560376  3.896390  0.0  0.0  0.0     0.0  0.0        NaN  2.0  3.0   \n",
       "4563  4.045097  2.847185  0.0  0.0  0.0     0.0  0.0  23.386643  1.0  1.0   \n",
       "\n",
       "      ...  C_026  F02_CN  nHDon   SpMax_B   Psi_i_A   nN     SM6_B  nArCOOR   \n",
       "0     ...    0.0     0.0    0.0  2.949000  1.591000  0.0  7.253000      0.0  \\\n",
       "1     ...    0.0     0.0    0.0  3.315000  1.967000  0.0  7.257000      0.0   \n",
       "2     ...    0.0     0.0    1.0       NaN  2.417000  0.0  7.601000      0.0   \n",
       "3     ...    0.0     0.0    1.0       NaN  5.000000  0.0  6.690000      0.0   \n",
       "4     ...    0.0     0.0    0.0  3.351000  2.405000  0.0  8.003000      0.0   \n",
       "...   ...    ...     ...    ...       ...       ...  ...       ...      ...   \n",
       "4559  ...    0.0     0.0    0.0  3.398382  3.241090  0.0  7.406748      0.0   \n",
       "4560  ...    0.0     0.0    1.0  3.429148  2.719309  0.0  7.511511      0.0   \n",
       "4561  ...    0.0     0.0    0.0  3.351666  2.729456  0.0  7.699324      0.0   \n",
       "4562  ...    0.0     0.0    0.0       NaN  3.059198  0.0  7.908802      0.0   \n",
       "4563  ...    0.0     2.0    2.0  3.032224  2.613357  1.0  6.863314      0.0   \n",
       "\n",
       "       nX  Biodegradable  \n",
       "0     0.0             RB  \n",
       "1     0.0             RB  \n",
       "2     0.0             RB  \n",
       "3     0.0             RB  \n",
       "4     NaN             RB  \n",
       "...   ...            ...  \n",
       "4559  0.0             RB  \n",
       "4560  0.0             RB  \n",
       "4561  0.0             RB  \n",
       "4562  0.0             RB  \n",
       "4563  0.0             RB  \n",
       "\n",
       "[4564 rows x 42 columns]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataSet= pd.read_csv(\"biodegradable_a.csv\", sep=\",\")\n",
    "dataSet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40c82ad1",
   "metadata": {},
   "source": [
    "### Remover os espaços em branco do DataSet:\n",
    "\n",
    "##### KNNInputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "1a62a96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['F01', 'C', 'nCp', 'HyWi_B', 'F03_CO', 'Me', 'nCIR', 'SpMax_A', 'SdO',\n",
      "       'nCrt', 'SpMax_B', 'Psi_i_A', 'nX'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpMax_L</th>\n",
       "      <th>J_Dz(e)</th>\n",
       "      <th>nHM</th>\n",
       "      <th>F01</th>\n",
       "      <th>F04</th>\n",
       "      <th>NssssC</th>\n",
       "      <th>nCb</th>\n",
       "      <th>C</th>\n",
       "      <th>nCp</th>\n",
       "      <th>nO</th>\n",
       "      <th>...</th>\n",
       "      <th>C_026</th>\n",
       "      <th>F02_CN</th>\n",
       "      <th>nHDon</th>\n",
       "      <th>SpMax_B</th>\n",
       "      <th>Psi_i_A</th>\n",
       "      <th>nN</th>\n",
       "      <th>SM6_B</th>\n",
       "      <th>nArCOOR</th>\n",
       "      <th>nX</th>\n",
       "      <th>Biodegradable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.919000</td>\n",
       "      <td>2.690900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.400000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.949000</td>\n",
       "      <td>1.591000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.253000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.170000</td>\n",
       "      <td>2.114400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.315000</td>\n",
       "      <td>1.967000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.257000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.932000</td>\n",
       "      <td>3.251200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.700000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.183760</td>\n",
       "      <td>2.417000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.601000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.709800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.091871</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.690000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.236000</td>\n",
       "      <td>3.394400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.400000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.351000</td>\n",
       "      <td>2.405000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.003000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4559</th>\n",
       "      <td>4.175650</td>\n",
       "      <td>3.454649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.398382</td>\n",
       "      <td>3.241090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.406748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4560</th>\n",
       "      <td>3.853731</td>\n",
       "      <td>2.747142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.429148</td>\n",
       "      <td>2.719309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.511511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4561</th>\n",
       "      <td>4.294771</td>\n",
       "      <td>3.471226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.422154</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.351666</td>\n",
       "      <td>2.729456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.699324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4562</th>\n",
       "      <td>4.560376</td>\n",
       "      <td>3.896390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.872380</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.509342</td>\n",
       "      <td>3.059198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.908802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4563</th>\n",
       "      <td>4.045097</td>\n",
       "      <td>2.847185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.386643</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.032224</td>\n",
       "      <td>2.613357</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.863314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4564 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SpMax_L   J_Dz(e)  nHM  F01  F04  NssssC  nCb          C  nCp   nO   \n",
       "0     3.919000  2.690900  0.0  0.0  0.0     0.0  0.0  31.400000  2.0  0.0  \\\n",
       "1     4.170000  2.114400  0.0  0.0  0.0     0.0  0.0  30.800000  1.0  1.0   \n",
       "2     3.932000  3.251200  0.0  0.0  0.0     0.0  0.0  26.700000  2.0  4.0   \n",
       "3     3.000000  2.709800  0.0  0.0  0.0     0.0  0.0  20.000000  1.0  2.0   \n",
       "4     4.236000  3.394400  0.0  0.0  0.0     0.0  0.0  29.400000  2.0  4.0   \n",
       "...        ...       ...  ...  ...  ...     ...  ...        ...  ...  ...   \n",
       "4559  4.175650  3.454649  0.0  0.0  0.0     0.0  0.0  27.300000  2.0  2.0   \n",
       "4560  3.853731  2.747142  0.0  0.0  0.0     0.0  0.0  33.300000  0.0  0.0   \n",
       "4561  4.294771  3.471226  0.0  0.0  0.0     0.0  0.0  28.422154  2.0  2.0   \n",
       "4562  4.560376  3.896390  0.0  0.0  0.0     0.0  0.0  31.872380  2.0  3.0   \n",
       "4563  4.045097  2.847185  0.0  0.0  0.0     0.0  0.0  23.386643  1.0  1.0   \n",
       "\n",
       "      ...  C_026  F02_CN  nHDon   SpMax_B   Psi_i_A   nN     SM6_B  nArCOOR   \n",
       "0     ...    0.0     0.0    0.0  2.949000  1.591000  0.0  7.253000      0.0  \\\n",
       "1     ...    0.0     0.0    0.0  3.315000  1.967000  0.0  7.257000      0.0   \n",
       "2     ...    0.0     0.0    1.0  3.183760  2.417000  0.0  7.601000      0.0   \n",
       "3     ...    0.0     0.0    1.0  3.091871  5.000000  0.0  6.690000      0.0   \n",
       "4     ...    0.0     0.0    0.0  3.351000  2.405000  0.0  8.003000      0.0   \n",
       "...   ...    ...     ...    ...       ...       ...  ...       ...      ...   \n",
       "4559  ...    0.0     0.0    0.0  3.398382  3.241090  0.0  7.406748      0.0   \n",
       "4560  ...    0.0     0.0    1.0  3.429148  2.719309  0.0  7.511511      0.0   \n",
       "4561  ...    0.0     0.0    0.0  3.351666  2.729456  0.0  7.699324      0.0   \n",
       "4562  ...    0.0     0.0    0.0  3.509342  3.059198  0.0  7.908802      0.0   \n",
       "4563  ...    0.0     2.0    2.0  3.032224  2.613357  1.0  6.863314      0.0   \n",
       "\n",
       "       nX  Biodegradable  \n",
       "0     0.0             RB  \n",
       "1     0.0             RB  \n",
       "2     0.0             RB  \n",
       "3     0.0             RB  \n",
       "4     0.0             RB  \n",
       "...   ...            ...  \n",
       "4559  0.0             RB  \n",
       "4560  0.0             RB  \n",
       "4561  0.0             RB  \n",
       "4562  0.0             RB  \n",
       "4563  0.0             RB  \n",
       "\n",
       "[4564 rows x 42 columns]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Escolhemos 5 vizinhos de modo a obter uma valor médio para cada valor em falta \n",
    "# ou seja nem muito adaptado aos dados (overfitting) nem muito suave (underfitting)\n",
    "imputer = KNNImputer(n_neighbors=5, weights=\"uniform\");\n",
    "badColumns = dataSet.columns[dataSet.isnull().any()];\n",
    "\n",
    "print(badColumns)\n",
    "\n",
    "dataSet[badColumns] = imputer.fit_transform(dataSet[badColumns]);\n",
    "\n",
    "dataSet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e79debc4",
   "metadata": {},
   "source": [
    "Categorizar a variável Biodegradable em binário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "e873e885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpMax_L</th>\n",
       "      <th>J_Dz(e)</th>\n",
       "      <th>nHM</th>\n",
       "      <th>F01</th>\n",
       "      <th>F04</th>\n",
       "      <th>NssssC</th>\n",
       "      <th>nCb</th>\n",
       "      <th>C</th>\n",
       "      <th>nCp</th>\n",
       "      <th>nO</th>\n",
       "      <th>...</th>\n",
       "      <th>C_026</th>\n",
       "      <th>F02_CN</th>\n",
       "      <th>nHDon</th>\n",
       "      <th>SpMax_B</th>\n",
       "      <th>Psi_i_A</th>\n",
       "      <th>nN</th>\n",
       "      <th>SM6_B</th>\n",
       "      <th>nArCOOR</th>\n",
       "      <th>nX</th>\n",
       "      <th>Biodegradable_RB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.919000</td>\n",
       "      <td>2.690900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.400000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.949000</td>\n",
       "      <td>1.591000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.253000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.170000</td>\n",
       "      <td>2.114400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.315000</td>\n",
       "      <td>1.967000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.257000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.932000</td>\n",
       "      <td>3.251200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.700000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.183760</td>\n",
       "      <td>2.417000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.601000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.709800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.091871</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.690000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.236000</td>\n",
       "      <td>3.394400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.400000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.351000</td>\n",
       "      <td>2.405000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.003000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4559</th>\n",
       "      <td>4.175650</td>\n",
       "      <td>3.454649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.398382</td>\n",
       "      <td>3.241090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.406748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4560</th>\n",
       "      <td>3.853731</td>\n",
       "      <td>2.747142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.429148</td>\n",
       "      <td>2.719309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.511511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4561</th>\n",
       "      <td>4.294771</td>\n",
       "      <td>3.471226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.422154</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.351666</td>\n",
       "      <td>2.729456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.699324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4562</th>\n",
       "      <td>4.560376</td>\n",
       "      <td>3.896390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.872380</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.509342</td>\n",
       "      <td>3.059198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.908802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4563</th>\n",
       "      <td>4.045097</td>\n",
       "      <td>2.847185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.386643</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.032224</td>\n",
       "      <td>2.613357</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.863314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4564 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SpMax_L   J_Dz(e)  nHM  F01  F04  NssssC  nCb          C  nCp   nO   \n",
       "0     3.919000  2.690900  0.0  0.0  0.0     0.0  0.0  31.400000  2.0  0.0  \\\n",
       "1     4.170000  2.114400  0.0  0.0  0.0     0.0  0.0  30.800000  1.0  1.0   \n",
       "2     3.932000  3.251200  0.0  0.0  0.0     0.0  0.0  26.700000  2.0  4.0   \n",
       "3     3.000000  2.709800  0.0  0.0  0.0     0.0  0.0  20.000000  1.0  2.0   \n",
       "4     4.236000  3.394400  0.0  0.0  0.0     0.0  0.0  29.400000  2.0  4.0   \n",
       "...        ...       ...  ...  ...  ...     ...  ...        ...  ...  ...   \n",
       "4559  4.175650  3.454649  0.0  0.0  0.0     0.0  0.0  27.300000  2.0  2.0   \n",
       "4560  3.853731  2.747142  0.0  0.0  0.0     0.0  0.0  33.300000  0.0  0.0   \n",
       "4561  4.294771  3.471226  0.0  0.0  0.0     0.0  0.0  28.422154  2.0  2.0   \n",
       "4562  4.560376  3.896390  0.0  0.0  0.0     0.0  0.0  31.872380  2.0  3.0   \n",
       "4563  4.045097  2.847185  0.0  0.0  0.0     0.0  0.0  23.386643  1.0  1.0   \n",
       "\n",
       "      ...  C_026  F02_CN  nHDon   SpMax_B   Psi_i_A   nN     SM6_B  nArCOOR   \n",
       "0     ...    0.0     0.0    0.0  2.949000  1.591000  0.0  7.253000      0.0  \\\n",
       "1     ...    0.0     0.0    0.0  3.315000  1.967000  0.0  7.257000      0.0   \n",
       "2     ...    0.0     0.0    1.0  3.183760  2.417000  0.0  7.601000      0.0   \n",
       "3     ...    0.0     0.0    1.0  3.091871  5.000000  0.0  6.690000      0.0   \n",
       "4     ...    0.0     0.0    0.0  3.351000  2.405000  0.0  8.003000      0.0   \n",
       "...   ...    ...     ...    ...       ...       ...  ...       ...      ...   \n",
       "4559  ...    0.0     0.0    0.0  3.398382  3.241090  0.0  7.406748      0.0   \n",
       "4560  ...    0.0     0.0    1.0  3.429148  2.719309  0.0  7.511511      0.0   \n",
       "4561  ...    0.0     0.0    0.0  3.351666  2.729456  0.0  7.699324      0.0   \n",
       "4562  ...    0.0     0.0    0.0  3.509342  3.059198  0.0  7.908802      0.0   \n",
       "4563  ...    0.0     2.0    2.0  3.032224  2.613357  1.0  6.863314      0.0   \n",
       "\n",
       "       nX  Biodegradable_RB  \n",
       "0     0.0                 1  \n",
       "1     0.0                 1  \n",
       "2     0.0                 1  \n",
       "3     0.0                 1  \n",
       "4     0.0                 1  \n",
       "...   ...               ...  \n",
       "4559  0.0                 1  \n",
       "4560  0.0                 1  \n",
       "4561  0.0                 1  \n",
       "4562  0.0                 1  \n",
       "4563  0.0                 1  \n",
       "\n",
       "[4564 rows x 42 columns]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binario = pd.get_dummies(dataSet, columns=['Biodegradable'], prefix=['Biodegradable']);\n",
    "\n",
    "dataSet = pd.concat([dataSet, binario['Biodegradable_RB']], axis=1)\n",
    "dataSet = dataSet.drop('Biodegradable', axis=1)\n",
    "dataSet['Biodegradable_RB'] = dataSet['Biodegradable_RB'].astype(int)\n",
    "\n",
    "\n",
    "dataSet\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e05a65a",
   "metadata": {},
   "source": [
    "### Scaling data... To see wich is the best scaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "56529972",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, matthews_corrcoef, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler,StandardScaler\n",
    "\n",
    "# Método retirado do notebook: EC_TP04.ipynb -> 2022/2023\n",
    "# Este método imprime um conjunto de estatísticas sobre um determinado modelo treinado e as suas previsoes.\n",
    "def printClassResults(truth, preds):\n",
    "    print(\"The Accuracy is: %7.4f\" % accuracy_score(truth, preds))\n",
    "    print(\"The Precision is: %7.4f\" % precision_score(truth, preds))\n",
    "    print(\"The Recall is: %7.4f\" % recall_score(truth, preds))\n",
    "    print(\"The F1 score is: %7.4f\" % f1_score(truth, preds))\n",
    "    print(\"The Matthews correlation coefficient is: %7.4f\" % matthews_corrcoef(truth, preds))\n",
    "    #print()\n",
    "    #print(\"This is the Confusion Matrix\")\n",
    "    #print(pd.DataFrame(confusion_matrix(truth, preds)))\n",
    "\n",
    "\n",
    "scalers = {\n",
    "    'StandardScaler': StandardScaler(),\n",
    "    'RobustScaler': RobustScaler(),\n",
    "    'MinMaxScaler': MinMaxScaler()\n",
    "}\n",
    "\n",
    "def testScalers(scalers, model, results,Xtrain,Xtest,Ytrain,Ytest):\n",
    "\n",
    "    for scaler_name, scaler in scalers.items():\n",
    "        X_train_scaled = scaler.fit_transform(Xtrain)\n",
    "        X_test_scaled = scaler.transform(Xtest)\n",
    "        \n",
    "        model.fit(X_train_scaled, Ytrain)\n",
    "        \n",
    "        Ypred = model.predict(X_test_scaled)\n",
    "        \n",
    "        accuracy = accuracy_score(Ytest, Ypred)\n",
    "        \n",
    "        results[scaler_name] = accuracy\n",
    "\n",
    "        print(\"Scaler: \",scaler_name,\"\\n\");\n",
    "        printClassResults(Ytest,Ypred);\n",
    "        print()\n",
    "\n",
    "def scaleData(scaler,Xtrain,Xtest):\n",
    "    X_train_scaled = scaler.fit_transform(Xtrain)\n",
    "    X_test_scaled = scaler.transform(Xtest)\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63c2bb71",
   "metadata": {},
   "source": [
    "##### Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "6f142122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler:  StandardScaler \n",
      "\n",
      "The Accuracy is:  0.9608\n",
      "The Precision is:  0.9634\n",
      "The Recall is:  0.9914\n",
      "The F1 score is:  0.9772\n",
      "The Matthews correlation coefficient is:  0.8441\n",
      "\n",
      "Scaler:  RobustScaler \n",
      "\n",
      "The Accuracy is:  0.9575\n",
      "The Precision is:  0.9611\n",
      "The Recall is:  0.9898\n",
      "The F1 score is:  0.9753\n",
      "The Matthews correlation coefficient is:  0.8304\n",
      "\n",
      "Scaler:  MinMaxScaler \n",
      "\n",
      "The Accuracy is:  0.9416\n",
      "The Precision is:  0.9425\n",
      "The Recall is:  0.9914\n",
      "The F1 score is:  0.9663\n",
      "The Matthews correlation coefficient is:  0.7612\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Temos que X sao as features e o Y é a variavel de classificação\n",
    "X = dataSet.drop('Biodegradable_RB', axis=1)\n",
    "y = dataSet['Biodegradable_RB']\n",
    "\n",
    "# Faz-se a divisao entre teste e treino \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=22)\n",
    "\n",
    "results = {}\n",
    "\n",
    "testScalers(scalers,LogisticRegression(max_iter=1000,random_state=0),results,X_train,X_test,y_train,y_test);\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4988eceb",
   "metadata": {},
   "source": [
    "Tendo em conta os resultados para o Logistic Regression temos que o **Standart Scaler** obteve melhores resultados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99d48e2c",
   "metadata": {},
   "source": [
    "#### Decision Trees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "58c3aaa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler:  StandardScaler \n",
      "\n",
      "The Accuracy is:  0.9549\n",
      "The Precision is:  0.9718\n",
      "The Recall is:  0.9749\n",
      "The F1 score is:  0.9734\n",
      "The Matthews correlation coefficient is:  0.8262\n",
      "\n",
      "Scaler:  RobustScaler \n",
      "\n",
      "The Accuracy is:  0.9542\n",
      "The Precision is:  0.9748\n",
      "The Recall is:  0.9710\n",
      "The F1 score is:  0.9729\n",
      "The Matthews correlation coefficient is:  0.8264\n",
      "\n",
      "Scaler:  MinMaxScaler \n",
      "\n",
      "The Accuracy is:  0.9569\n",
      "The Precision is:  0.9734\n",
      "The Recall is:  0.9757\n",
      "The F1 score is:  0.9745\n",
      "The Matthews correlation coefficient is:  0.8342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Temos que X sao as features e o Y é a variavel de classificação\n",
    "X = dataSet.drop('Biodegradable_RB', axis=1)\n",
    "y = dataSet['Biodegradable_RB']\n",
    "\n",
    "# Faz-se a divisao entre teste e treino \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=22)\n",
    "\n",
    "results = {}\n",
    "\n",
    "testScalers(scalers,DecisionTreeClassifier(),results,X_train,X_test,y_train,y_test);\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e10a4237",
   "metadata": {},
   "source": [
    "Tendo em conta os resultados para as Decision Trees temos que o **Robust Scaler** obteve melhores resultados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8cb0dc02",
   "metadata": {},
   "source": [
    "#### Random Forests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "ce11719f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler:  StandardScaler \n",
      "\n",
      "The Accuracy is:  0.9728\n",
      "The Precision is:  0.9798\n",
      "The Recall is:  0.9882\n",
      "The F1 score is:  0.9840\n",
      "The Matthews correlation coefficient is:  0.8942\n",
      "\n",
      "Scaler:  RobustScaler \n",
      "\n",
      "The Accuracy is:  0.9735\n",
      "The Precision is:  0.9813\n",
      "The Recall is:  0.9874\n",
      "The F1 score is:  0.9844\n",
      "The Matthews correlation coefficient is:  0.8972\n",
      "\n",
      "Scaler:  MinMaxScaler \n",
      "\n",
      "The Accuracy is:  0.9715\n",
      "The Precision is:  0.9782\n",
      "The Recall is:  0.9882\n",
      "The F1 score is:  0.9832\n",
      "The Matthews correlation coefficient is:  0.8888\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Temos que X sao as features e o Y é a variavel de classificação\n",
    "X = dataSet.drop('Biodegradable_RB', axis=1)\n",
    "y = dataSet['Biodegradable_RB']\n",
    "\n",
    "# Faz-se a divisao entre teste e treino \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=22)\n",
    "\n",
    "results = {}\n",
    "\n",
    "testScalers(scalers,RandomForestClassifier(),results,X_train,X_test,y_train,y_test);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f434990",
   "metadata": {},
   "source": [
    "Tendo em conta os resultados para o Random Forests temos que o **MinMaxScaler** obteve melhores resultados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "740b639e",
   "metadata": {},
   "source": [
    "####"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e323895",
   "metadata": {},
   "source": [
    "#### SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "31dbd0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler:  StandardScaler \n",
      "\n",
      "The Accuracy is:  0.9688\n",
      "The Precision is:  0.9716\n",
      "The Recall is:  0.9922\n",
      "The F1 score is:  0.9817\n",
      "The Matthews correlation coefficient is:  0.8770\n",
      "\n",
      "Scaler:  RobustScaler \n",
      "\n",
      "The Accuracy is:  0.9608\n",
      "The Precision is:  0.9620\n",
      "The Recall is:  0.9929\n",
      "The F1 score is:  0.9772\n",
      "The Matthews correlation coefficient is:  0.8440\n",
      "\n",
      "Scaler:  MinMaxScaler \n",
      "\n",
      "The Accuracy is:  0.9502\n",
      "The Precision is:  0.9531\n",
      "The Recall is:  0.9898\n",
      "The F1 score is:  0.9711\n",
      "The Matthews correlation coefficient is:  0.7992\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Temos que X sao as features e o Y é a variavel de classificação\n",
    "X = dataSet.drop('Biodegradable_RB', axis=1)\n",
    "y = dataSet['Biodegradable_RB']\n",
    "\n",
    "# Faz-se a divisao entre teste e treino \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=22)\n",
    "\n",
    "results = {}\n",
    "\n",
    "testScalers(scalers,SVC(),results,X_train,X_test,y_train,y_test);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab397a8c",
   "metadata": {},
   "source": [
    "Tendo em conta os resultados para o SVM temos que o **Standart Scaler** obteve melhores resultados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d815a49",
   "metadata": {},
   "source": [
    "#### Tendo em conta que em todos os testes usando 4 modelos diferentes, o StandartScaler obteve os melhores resultados em 2 dos 4 testes, *a não ser que seja utilizado no final o modelo Decision Trees, ou Random Forests mas mesmo com estes modelos os valores do StandartScaler continuam bem positivos*, deve ser utilizado o método de scaling : **StandartScaler**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fdfc5e56",
   "metadata": {},
   "source": [
    "## Identificar e remover colunas irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "cf0404f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biodegradable_RB    1.000000\n",
      "LOC                 0.207218\n",
      "nO                  0.141070\n",
      "Mi                  0.140804\n",
      "TI2_L               0.109940\n",
      "Psi_i_A             0.097798\n",
      "nArCOOR             0.079910\n",
      "SdO                 0.065328\n",
      "J_Dz(e)             0.017860\n",
      "F03_CO             -0.006808\n",
      "Psi_i_1d           -0.023884\n",
      "nCp                -0.062366\n",
      "nHDon              -0.074595\n",
      "Me                 -0.091242\n",
      "nN_N               -0.091457\n",
      "SdssC              -0.093929\n",
      "nCRX3              -0.150175\n",
      "N_073              -0.157655\n",
      "B04                -0.163512\n",
      "F01                -0.164858\n",
      "C                  -0.173525\n",
      "nCIR               -0.191703\n",
      "nCrt               -0.196624\n",
      "B01                -0.203406\n",
      "nArNO2             -0.244192\n",
      "HyWi_B             -0.278358\n",
      "NssssC             -0.279600\n",
      "SM6_L              -0.284736\n",
      "SpMax_A            -0.311502\n",
      "nX                 -0.316797\n",
      "SpMax_L            -0.344925\n",
      "SpPosA_B           -0.348069\n",
      "SpMax_B            -0.362397\n",
      "F04                -0.384562\n",
      "nN                 -0.390646\n",
      "nCb                -0.390673\n",
      "B03                -0.393854\n",
      "F03                -0.400053\n",
      "SM6_B              -0.401354\n",
      "C_026              -0.427643\n",
      "F02_CN             -0.428333\n",
      "nHM                -0.466120\n",
      "Name: Biodegradable_RB, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "correlation_matrix = dataSet.corr()\n",
    "target_correlation = correlation_matrix['Biodegradable_RB'].sort_values(ascending=False)\n",
    "print(target_correlation)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf53a534",
   "metadata": {},
   "source": [
    "#### Using Correlation selection method :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "d1d6ab13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import f1_score, confusion_matrix,matthews_corrcoef, precision_score, recall_score\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "8aa4f276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     1.000000\n",
      "1    -0.339905\n",
      "2     0.010871\n",
      "3    -0.477725\n",
      "4    -0.177617\n",
      "5    -0.365627\n",
      "6    -0.290618\n",
      "7    -0.385291\n",
      "8    -0.170515\n",
      "9    -0.036754\n",
      "10    0.149124\n",
      "11   -0.381619\n",
      "12   -0.086479\n",
      "13   -0.267211\n",
      "14    0.208538\n",
      "15   -0.279377\n",
      "16    0.006174\n",
      "17   -0.098625\n",
      "18    0.135689\n",
      "19   -0.102844\n",
      "20   -0.245024\n",
      "21   -0.155193\n",
      "22   -0.345045\n",
      "23   -0.173646\n",
      "24   -0.202546\n",
      "25   -0.397135\n",
      "26   -0.149704\n",
      "27   -0.307748\n",
      "28   -0.032562\n",
      "29   -0.161298\n",
      "30    0.066465\n",
      "31    0.112354\n",
      "32   -0.197523\n",
      "33   -0.424724\n",
      "34   -0.415821\n",
      "35   -0.060208\n",
      "36   -0.360472\n",
      "37    0.088014\n",
      "38   -0.381471\n",
      "39   -0.391806\n",
      "40    0.089395\n",
      "41   -0.333509\n",
      "Name: 0, dtype: float64\n",
      "[0, 2, 4, 5, 6, 10, 12, 13, 14, 19, 21, 23, 24, 26, 32, 33, 35, 37, 38, 40]\n"
     ]
    }
   ],
   "source": [
    "#Escala-se a data a ser utilizada, com o StandartScaler (melhor dos testes)\n",
    "Xtrain_scaled, Xtest_scaled = scaleData(StandardScaler(),X_train,X_test)\n",
    "\n",
    "#print(pd.DataFrame(Xtrain_scaled))\n",
    "N,M=Xtrain_scaled.shape\n",
    "N,M\n",
    "v=np.hstack((y_train.values.reshape((N,1)), Xtrain_scaled))\n",
    "#print(pd.DataFrame(v))\n",
    "corr_data = pd.DataFrame(np.corrcoef(v.T))\n",
    "first_column = corr_data.iloc[:, 0]\n",
    "print(first_column);\n",
    "positive = True\n",
    "counter=1;\n",
    "\n",
    "selColIndexs = []\n",
    "\n",
    "while positive and counter<len(first_column):\n",
    "    \n",
    "    value = first_column.iloc[counter];\n",
    "\n",
    "    if(value>0.2 or value<-0.2):\n",
    "        selColIndexs.append(counter-1);\n",
    "    counter+=1\n",
    "        \n",
    "# indices (já sem a coluna adicionada da variavel alvo) das features com um correlation score maior que 0 em relacao a variavel Biodegradable;\n",
    "print(selColIndexs);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "ee373216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teste com * TODAS * as variáveis - utilizando o StandartScaler:\n",
      "Scaler:  StandartScaler \n",
      "\n",
      "The Accuracy is:  0.9708\n",
      "The Precision is:  0.9797\n",
      "The Recall is:  0.9859\n",
      "The F1 score is:  0.9828\n",
      "The Matthews correlation coefficient is:  0.8869\n",
      "\n",
      "\n",
      "\n",
      " Teste com * APENAS AS VARIÀVEIS SELECIONADAS *  - utilizando o StandartScaler:\n",
      "Scaler:  StandartScaler \n",
      "\n",
      "The Accuracy is:  0.9376\n",
      "The Precision is:  0.9403\n",
      "The Recall is:  0.9890\n",
      "The F1 score is:  0.9640\n",
      "The Matthews correlation coefficient is:  0.7436\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Vamos então testar se obtemos melhores resultados agora com apenas as variaveis selecionadas\n",
    "# Para o objetivo deste teste iremos usar RandomForests pois foi um dos modelos melhor classificado\n",
    "# quando procedemos ao teste dos scalers.\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Temos que X sao as features e o Y é a variavel de classificação\n",
    "X = dataSet.drop('Biodegradable_RB', axis=1)\n",
    "y = dataSet['Biodegradable_RB']\n",
    "\n",
    "#print(X);\n",
    "\n",
    "#print(\"\\n\\nagora o Y\\n\\n\")\n",
    "#print(y);\n",
    "# Faz-se a divisao entre teste e treino \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=22)\n",
    "\n",
    "results = {}\n",
    "print(\"Teste com * TODAS * as variáveis - utilizando o StandartScaler:\")\n",
    "testScalers({'StandartScaler':StandardScaler()},RandomForestClassifier(),results,X_train,X_test,y_train,y_test);\n",
    "\n",
    "newXtrain = X_train.iloc[:, selColIndexs];\n",
    "newXtest = X_test.iloc[:, selColIndexs];\n",
    "\n",
    "\n",
    "print(\"\\n\\n Teste com * APENAS AS VARIÀVEIS SELECIONADAS *  - utilizando o StandartScaler:\");\n",
    "testScalers({'StandartScaler':StandardScaler()},RandomForestClassifier(),results,newXtrain,newXtest,y_train,y_test);\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f54e872",
   "metadata": {},
   "source": [
    "Discucao...\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6f93f86",
   "metadata": {},
   "source": [
    "#### Using Stepwise Feature selection method :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "c230f4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features selected are columns:  [ 2  5  6  9 10 15 18 19 22 23 25 28 29 30 32 33 34 37 38 40]\n"
     ]
    }
   ],
   "source": [
    "#ESTE PASSO COSTUMA DEMORAR CERCA DE 4 MIN A EXECUTAR !!\n",
    "\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "# Temos que X sao as features e o Y é a variavel de classificação\n",
    "X = dataSet.drop('Biodegradable_RB', axis=1)\n",
    "y = dataSet['Biodegradable_RB']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=22)\n",
    "\n",
    "Xtrain_scaled, Xtest_scaled = scaleData(StandardScaler(),X_train,X_test)\n",
    "\n",
    "N,M=Xtrain_scaled.shape\n",
    "\n",
    "#using RandomForest for sequential feature selection\n",
    "clf = RandomForestClassifier()\n",
    "sfs = SequentialFeatureSelector(clf, n_features_to_select=20)\n",
    "sfs.fit(Xtrain_scaled, y_train)\n",
    "\n",
    "#get the relevant columns\n",
    "features=sfs.get_support()\n",
    "Features_selected =np.arange(M)[features]\n",
    "print(\"The features selected are columns: \", Features_selected)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "cdf6071e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teste com * TODAS * as variáveis - utilizando o StandartScaler:\n",
      "Scaler:  StandartScaler \n",
      "\n",
      "The Accuracy is:  0.9715\n",
      "The Precision is:  0.9782\n",
      "The Recall is:  0.9882\n",
      "The F1 score is:  0.9832\n",
      "The Matthews correlation coefficient is:  0.8888\n",
      "\n",
      "\n",
      "\n",
      " Teste com * APENAS AS VARIÀVEIS SELECIONADAS *  - utilizando o StandartScaler:\n",
      "Scaler:  StandartScaler \n",
      "\n",
      "The Accuracy is:  0.9715\n",
      "The Precision is:  0.9782\n",
      "The Recall is:  0.9882\n",
      "The F1 score is:  0.9832\n",
      "The Matthews correlation coefficient is:  0.8888\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Teste com * TODAS * as variáveis - utilizando o StandartScaler:\")\n",
    "testScalers({'StandartScaler':StandardScaler()},RandomForestClassifier(),results,X_train,X_test,y_train,y_test);\n",
    "\n",
    "newXtrain =sfs.transform(Xtrain_scaled)\n",
    "newXtest = sfs.transform(Xtest_scaled)\n",
    "\n",
    "\n",
    "print(\"\\n\\n Teste com * APENAS AS VARIÀVEIS SELECIONADAS *  - utilizando o StandartScaler:\");\n",
    "testScalers({'StandartScaler':StandardScaler()},RandomForestClassifier(),results,newXtrain,newXtest,y_train,y_test);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "058a8758",
   "metadata": {},
   "source": [
    "#### Using PCA selection method :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "59414573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teste com * TODAS * as variáveis - utilizando o StandartScaler:\n",
      "Scaler:  StandartScaler \n",
      "\n",
      "The Accuracy is:  0.9721\n",
      "The Precision is:  0.9790\n",
      "The Recall is:  0.9882\n",
      "The F1 score is:  0.9836\n",
      "The Matthews correlation coefficient is:  0.8915\n",
      "\n",
      "PC0 - Variance explained:  0.1943 - Total Variance:  0.1943\n",
      "PC1 - Variance explained:  0.1135 - Total Variance:  0.3078\n",
      "PC2 - Variance explained:  0.1019 - Total Variance:  0.4097\n",
      "PC3 - Variance explained:  0.0822 - Total Variance:  0.4920\n",
      "PC4 - Variance explained:  0.0700 - Total Variance:  0.5619\n",
      "PC5 - Variance explained:  0.0504 - Total Variance:  0.6123\n",
      "PC6 - Variance explained:  0.0351 - Total Variance:  0.6474\n",
      "PC7 - Variance explained:  0.0315 - Total Variance:  0.6789\n",
      "PC8 - Variance explained:  0.0305 - Total Variance:  0.7094\n",
      "PC9 - Variance explained:  0.0284 - Total Variance:  0.7378\n",
      "PC10 - Variance explained:  0.0261 - Total Variance:  0.7639\n",
      "PC11 - Variance explained:  0.0248 - Total Variance:  0.7886\n",
      "PC12 - Variance explained:  0.0237 - Total Variance:  0.8124\n",
      "PC13 - Variance explained:  0.0207 - Total Variance:  0.8331\n",
      "PC14 - Variance explained:  0.0190 - Total Variance:  0.8520\n",
      "PC15 - Variance explained:  0.0163 - Total Variance:  0.8684\n",
      "PC16 - Variance explained:  0.0156 - Total Variance:  0.8840\n",
      "PC17 - Variance explained:  0.0140 - Total Variance:  0.8980\n",
      "PC18 - Variance explained:  0.0110 - Total Variance:  0.9090\n",
      "PC19 - Variance explained:  0.0102 - Total Variance:  0.9192\n",
      "\n",
      "(1507, 20)\n",
      "\n",
      "\n",
      " Teste com * APENAS AS VARIÀVEIS SELECIONADAS *  - utilizando o StandartScaler:\n",
      "Scaler:  StandartScaler \n",
      "\n",
      "The Accuracy is:  0.9615\n",
      "The Precision is:  0.9663\n",
      "The Recall is:  0.9890\n",
      "The F1 score is:  0.9775\n",
      "The Matthews correlation coefficient is:  0.8473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Temos que X sao as features e o Y é a variavel de classificação\n",
    "X = dataSet.drop('Biodegradable_RB', axis=1)\n",
    "y = dataSet['Biodegradable_RB']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=22)\n",
    "\n",
    "Xtrain_scaled, Xtest_scaled = scaleData(StandardScaler(),X_train,X_test)\n",
    "\n",
    "print(\"Teste com * TODAS * as variáveis - utilizando o StandartScaler:\")\n",
    "testScalers({'StandartScaler':StandardScaler()},RandomForestClassifier(),results,Xtrain_scaled,Xtest_scaled,y_train,y_test);\n",
    "\n",
    "#utilizamos 20 PCs pois após várias tentaivas é o valor que nos permite obter uma Total variance de pelo menos 90% \n",
    "pca = PCA(n_components=20) \n",
    "pca.fit(Xtrain_scaled)\n",
    "tve=0 #total variance explained\n",
    "for i, ve in enumerate(pca.explained_variance_ratio_):\n",
    "    tve+=ve\n",
    "    print(\"PC%d - Variance explained: %7.4f - Total Variance: %7.4f\" % (i, ve, tve) )\n",
    "print()\n",
    "#print(\"Actual Eigenvalues:\", pca.singular_values_)\n",
    "\n",
    "newX_train=pca.transform(Xtrain_scaled)\n",
    "newX_test=pca.transform(Xtest_scaled)\n",
    "\n",
    "print(newX_test.shape);\n",
    "\n",
    "print(\"\\n\\n Teste com * APENAS AS VARIÀVEIS SELECIONADAS *  - utilizando o StandartScaler:\");\n",
    "testScalers({'StandartScaler':StandardScaler()},RandomForestClassifier(),results,newX_train,newX_test,y_train,y_test);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "032381c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Temos que X sao as features e o Y é a variavel de classificação\n",
    "# X = dataSet.drop('Biodegradable_RB', axis=1)\n",
    "# y = dataSet['Biodegradable_RB']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=22)\n",
    "\n",
    "# Xtrain_scaled, Xtest_scaled = scaleData(StandardScaler(),X_train,X_test)\n",
    "# print(\"Teste com * TODAS * as variáveis - utilizando o StandartScaler:\")\n",
    "# testScalers({'StandartScaler':StandardScaler()},RandomForestClassifier(),results,Xtrain_scaled,Xtest_scaled,y_train,y_test);\n",
    "\n",
    "\n",
    "# X_pca = pca.fit_transform(Xtrain_scaled)\n",
    "\n",
    "# loadings = pca.components_\n",
    "\n",
    "# feature_count = {}\n",
    "\n",
    "# # Esta parte do código foi obtida com ajuda da ferramenta ChatGPT\n",
    "# for i, component in enumerate(loadings):\n",
    "#     feature_indices = np.argsort(np.abs(component))[::-1] \n",
    "#     contributing_features = feature_indices[:10]  \n",
    "#     for feature_index in contributing_features:\n",
    "#         feature_name = X.columns[feature_index]\n",
    "#         if feature_name in feature_count:\n",
    "#             feature_count[feature_name] += 1\n",
    "#         else:\n",
    "#             feature_count[feature_name] = 1\n",
    "\n",
    "# sorted_features = sorted(feature_count.items(), key=lambda x: x[1], reverse=True)[:20]\n",
    "\n",
    "\n",
    "# selected_feature_names = [feature for feature, count in sorted_features]\n",
    "\n",
    "# filtered_dataset = dataSet.loc[:, selected_feature_names]\n",
    "# filtered_dataset\n",
    "\n",
    "# # Temos que X sao as features e o Y é a variavel de classificação\n",
    "# X = filtered_dataset\n",
    "# y = dataSet['Biodegradable_RB']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=22)\n",
    "\n",
    "# Xtrain_scaled, Xtest_scaled = scaleData(StandardScaler(),X_train,X_test)\n",
    "\n",
    "\n",
    "# print(\"\\n\\n Teste com * APENAS AS VARIÀVEIS SELECIONADAS *  - utilizando o StandartScaler:\");\n",
    "# testScalers({'StandartScaler':StandardScaler()},RandomForestClassifier(),results,newX_train,newX_test,y_train,y_test);\n",
    "\n",
    "# print(\"Features selecionadas:\",selected_feature_names);\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54feb2b5",
   "metadata": {},
   "source": [
    "Tendo em conta os resultados, os métodos que mais afetam a dimensionalidade são a Correlation e a SFS mas o que melhores resultados apresenta é o PCA com um accuracy: 0.9615 e um F1 score: 0.9775 face aos 0.9721 e 0.9890 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
