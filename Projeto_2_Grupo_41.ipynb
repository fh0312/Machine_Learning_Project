{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b877ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpMax_L</th>\n",
       "      <th>J_Dz(e)</th>\n",
       "      <th>nHM</th>\n",
       "      <th>F01</th>\n",
       "      <th>F04</th>\n",
       "      <th>NssssC</th>\n",
       "      <th>nCb</th>\n",
       "      <th>C</th>\n",
       "      <th>nCp</th>\n",
       "      <th>nO</th>\n",
       "      <th>...</th>\n",
       "      <th>C_026</th>\n",
       "      <th>F02_CN</th>\n",
       "      <th>nHDon</th>\n",
       "      <th>SpMax_B</th>\n",
       "      <th>Psi_i_A</th>\n",
       "      <th>nN</th>\n",
       "      <th>SM6_B</th>\n",
       "      <th>nArCOOR</th>\n",
       "      <th>nX</th>\n",
       "      <th>Biodegradable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.919000</td>\n",
       "      <td>2.690900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.400000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.949000</td>\n",
       "      <td>1.591000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.253000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.170000</td>\n",
       "      <td>2.114400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.315000</td>\n",
       "      <td>1.967000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.257000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.932000</td>\n",
       "      <td>3.251200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.700000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.417000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.601000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.709800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.690000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.236000</td>\n",
       "      <td>3.394400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.400000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.351000</td>\n",
       "      <td>2.405000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.003000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4559</th>\n",
       "      <td>4.175650</td>\n",
       "      <td>3.454649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.398382</td>\n",
       "      <td>3.241090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.406748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4560</th>\n",
       "      <td>3.853731</td>\n",
       "      <td>2.747142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.429148</td>\n",
       "      <td>2.719309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.511511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4561</th>\n",
       "      <td>4.294771</td>\n",
       "      <td>3.471226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.422154</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.351666</td>\n",
       "      <td>2.729456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.699324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4562</th>\n",
       "      <td>4.560376</td>\n",
       "      <td>3.896390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.059198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.908802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4563</th>\n",
       "      <td>4.045097</td>\n",
       "      <td>2.847185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.386643</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.032224</td>\n",
       "      <td>2.613357</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.863314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4564 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SpMax_L   J_Dz(e)  nHM  F01  F04  NssssC  nCb          C  nCp   nO   \n",
       "0     3.919000  2.690900  0.0  0.0  0.0     0.0  0.0  31.400000  2.0  0.0  \\\n",
       "1     4.170000  2.114400  0.0  0.0  0.0     0.0  0.0  30.800000  1.0  1.0   \n",
       "2     3.932000  3.251200  0.0  0.0  0.0     0.0  0.0  26.700000  2.0  4.0   \n",
       "3     3.000000  2.709800  0.0  0.0  0.0     0.0  0.0  20.000000  NaN  2.0   \n",
       "4     4.236000  3.394400  0.0  0.0  0.0     0.0  0.0  29.400000  2.0  4.0   \n",
       "...        ...       ...  ...  ...  ...     ...  ...        ...  ...  ...   \n",
       "4559  4.175650  3.454649  0.0  0.0  0.0     0.0  0.0  27.300000  2.0  2.0   \n",
       "4560  3.853731  2.747142  0.0  NaN  0.0     0.0  0.0  33.300000  0.0  0.0   \n",
       "4561  4.294771  3.471226  0.0  0.0  0.0     0.0  0.0  28.422154  2.0  2.0   \n",
       "4562  4.560376  3.896390  0.0  0.0  0.0     0.0  0.0        NaN  2.0  3.0   \n",
       "4563  4.045097  2.847185  0.0  0.0  0.0     0.0  0.0  23.386643  1.0  1.0   \n",
       "\n",
       "      ...  C_026  F02_CN  nHDon   SpMax_B   Psi_i_A   nN     SM6_B  nArCOOR   \n",
       "0     ...    0.0     0.0    0.0  2.949000  1.591000  0.0  7.253000      0.0  \\\n",
       "1     ...    0.0     0.0    0.0  3.315000  1.967000  0.0  7.257000      0.0   \n",
       "2     ...    0.0     0.0    1.0       NaN  2.417000  0.0  7.601000      0.0   \n",
       "3     ...    0.0     0.0    1.0       NaN  5.000000  0.0  6.690000      0.0   \n",
       "4     ...    0.0     0.0    0.0  3.351000  2.405000  0.0  8.003000      0.0   \n",
       "...   ...    ...     ...    ...       ...       ...  ...       ...      ...   \n",
       "4559  ...    0.0     0.0    0.0  3.398382  3.241090  0.0  7.406748      0.0   \n",
       "4560  ...    0.0     0.0    1.0  3.429148  2.719309  0.0  7.511511      0.0   \n",
       "4561  ...    0.0     0.0    0.0  3.351666  2.729456  0.0  7.699324      0.0   \n",
       "4562  ...    0.0     0.0    0.0       NaN  3.059198  0.0  7.908802      0.0   \n",
       "4563  ...    0.0     2.0    2.0  3.032224  2.613357  1.0  6.863314      0.0   \n",
       "\n",
       "       nX  Biodegradable  \n",
       "0     0.0             RB  \n",
       "1     0.0             RB  \n",
       "2     0.0             RB  \n",
       "3     0.0             RB  \n",
       "4     NaN             RB  \n",
       "...   ...            ...  \n",
       "4559  0.0             RB  \n",
       "4560  0.0             RB  \n",
       "4561  0.0             RB  \n",
       "4562  0.0             RB  \n",
       "4563  0.0             RB  \n",
       "\n",
       "[4564 rows x 42 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataSet= pd.read_csv(\"biodegradable_a.csv\", sep=\",\")\n",
    "dataSet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40c82ad1",
   "metadata": {},
   "source": [
    "### Remover os espaços em branco do DataSet:\n",
    "\n",
    "##### KNNInputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a62a96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['F01', 'C', 'nCp', 'HyWi_B', 'F03_CO', 'Me', 'nCIR', 'SpMax_A', 'SdO',\n",
      "       'nCrt', 'SpMax_B', 'Psi_i_A', 'nX'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpMax_L</th>\n",
       "      <th>J_Dz(e)</th>\n",
       "      <th>nHM</th>\n",
       "      <th>F01</th>\n",
       "      <th>F04</th>\n",
       "      <th>NssssC</th>\n",
       "      <th>nCb</th>\n",
       "      <th>C</th>\n",
       "      <th>nCp</th>\n",
       "      <th>nO</th>\n",
       "      <th>...</th>\n",
       "      <th>C_026</th>\n",
       "      <th>F02_CN</th>\n",
       "      <th>nHDon</th>\n",
       "      <th>SpMax_B</th>\n",
       "      <th>Psi_i_A</th>\n",
       "      <th>nN</th>\n",
       "      <th>SM6_B</th>\n",
       "      <th>nArCOOR</th>\n",
       "      <th>nX</th>\n",
       "      <th>Biodegradable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.919000</td>\n",
       "      <td>2.690900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.400000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.949000</td>\n",
       "      <td>1.591000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.253000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.170000</td>\n",
       "      <td>2.114400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.315000</td>\n",
       "      <td>1.967000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.257000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.932000</td>\n",
       "      <td>3.251200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.700000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.183760</td>\n",
       "      <td>2.417000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.601000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.709800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.091871</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.690000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.236000</td>\n",
       "      <td>3.394400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.400000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.351000</td>\n",
       "      <td>2.405000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.003000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4559</th>\n",
       "      <td>4.175650</td>\n",
       "      <td>3.454649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.398382</td>\n",
       "      <td>3.241090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.406748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4560</th>\n",
       "      <td>3.853731</td>\n",
       "      <td>2.747142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.429148</td>\n",
       "      <td>2.719309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.511511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4561</th>\n",
       "      <td>4.294771</td>\n",
       "      <td>3.471226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.422154</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.351666</td>\n",
       "      <td>2.729456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.699324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4562</th>\n",
       "      <td>4.560376</td>\n",
       "      <td>3.896390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.872380</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.509342</td>\n",
       "      <td>3.059198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.908802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4563</th>\n",
       "      <td>4.045097</td>\n",
       "      <td>2.847185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.386643</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.032224</td>\n",
       "      <td>2.613357</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.863314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4564 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SpMax_L   J_Dz(e)  nHM  F01  F04  NssssC  nCb          C  nCp   nO   \n",
       "0     3.919000  2.690900  0.0  0.0  0.0     0.0  0.0  31.400000  2.0  0.0  \\\n",
       "1     4.170000  2.114400  0.0  0.0  0.0     0.0  0.0  30.800000  1.0  1.0   \n",
       "2     3.932000  3.251200  0.0  0.0  0.0     0.0  0.0  26.700000  2.0  4.0   \n",
       "3     3.000000  2.709800  0.0  0.0  0.0     0.0  0.0  20.000000  1.0  2.0   \n",
       "4     4.236000  3.394400  0.0  0.0  0.0     0.0  0.0  29.400000  2.0  4.0   \n",
       "...        ...       ...  ...  ...  ...     ...  ...        ...  ...  ...   \n",
       "4559  4.175650  3.454649  0.0  0.0  0.0     0.0  0.0  27.300000  2.0  2.0   \n",
       "4560  3.853731  2.747142  0.0  0.0  0.0     0.0  0.0  33.300000  0.0  0.0   \n",
       "4561  4.294771  3.471226  0.0  0.0  0.0     0.0  0.0  28.422154  2.0  2.0   \n",
       "4562  4.560376  3.896390  0.0  0.0  0.0     0.0  0.0  31.872380  2.0  3.0   \n",
       "4563  4.045097  2.847185  0.0  0.0  0.0     0.0  0.0  23.386643  1.0  1.0   \n",
       "\n",
       "      ...  C_026  F02_CN  nHDon   SpMax_B   Psi_i_A   nN     SM6_B  nArCOOR   \n",
       "0     ...    0.0     0.0    0.0  2.949000  1.591000  0.0  7.253000      0.0  \\\n",
       "1     ...    0.0     0.0    0.0  3.315000  1.967000  0.0  7.257000      0.0   \n",
       "2     ...    0.0     0.0    1.0  3.183760  2.417000  0.0  7.601000      0.0   \n",
       "3     ...    0.0     0.0    1.0  3.091871  5.000000  0.0  6.690000      0.0   \n",
       "4     ...    0.0     0.0    0.0  3.351000  2.405000  0.0  8.003000      0.0   \n",
       "...   ...    ...     ...    ...       ...       ...  ...       ...      ...   \n",
       "4559  ...    0.0     0.0    0.0  3.398382  3.241090  0.0  7.406748      0.0   \n",
       "4560  ...    0.0     0.0    1.0  3.429148  2.719309  0.0  7.511511      0.0   \n",
       "4561  ...    0.0     0.0    0.0  3.351666  2.729456  0.0  7.699324      0.0   \n",
       "4562  ...    0.0     0.0    0.0  3.509342  3.059198  0.0  7.908802      0.0   \n",
       "4563  ...    0.0     2.0    2.0  3.032224  2.613357  1.0  6.863314      0.0   \n",
       "\n",
       "       nX  Biodegradable  \n",
       "0     0.0             RB  \n",
       "1     0.0             RB  \n",
       "2     0.0             RB  \n",
       "3     0.0             RB  \n",
       "4     0.0             RB  \n",
       "...   ...            ...  \n",
       "4559  0.0             RB  \n",
       "4560  0.0             RB  \n",
       "4561  0.0             RB  \n",
       "4562  0.0             RB  \n",
       "4563  0.0             RB  \n",
       "\n",
       "[4564 rows x 42 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Escolhemos 5 vizinhos de modo a obter uma valor médio para cada valor em falta \n",
    "# ou seja nem muito adaptado aos dados (overfitting) nem muito suave (underfitting)\n",
    "imputer = KNNImputer(n_neighbors=5, weights=\"uniform\");\n",
    "badColumns = dataSet.columns[dataSet.isnull().any()];\n",
    "\n",
    "print(badColumns)\n",
    "\n",
    "dataSet[badColumns] = imputer.fit_transform(dataSet[badColumns]);\n",
    "\n",
    "dataSet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e79debc4",
   "metadata": {},
   "source": [
    "Categorizar a variável Biodegradable em binário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e873e885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpMax_L</th>\n",
       "      <th>J_Dz(e)</th>\n",
       "      <th>nHM</th>\n",
       "      <th>F01</th>\n",
       "      <th>F04</th>\n",
       "      <th>NssssC</th>\n",
       "      <th>nCb</th>\n",
       "      <th>C</th>\n",
       "      <th>nCp</th>\n",
       "      <th>nO</th>\n",
       "      <th>...</th>\n",
       "      <th>C_026</th>\n",
       "      <th>F02_CN</th>\n",
       "      <th>nHDon</th>\n",
       "      <th>SpMax_B</th>\n",
       "      <th>Psi_i_A</th>\n",
       "      <th>nN</th>\n",
       "      <th>SM6_B</th>\n",
       "      <th>nArCOOR</th>\n",
       "      <th>nX</th>\n",
       "      <th>Biodegradable_RB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.919000</td>\n",
       "      <td>2.690900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.400000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.949000</td>\n",
       "      <td>1.591000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.253000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.170000</td>\n",
       "      <td>2.114400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.315000</td>\n",
       "      <td>1.967000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.257000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.932000</td>\n",
       "      <td>3.251200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.700000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.183760</td>\n",
       "      <td>2.417000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.601000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.709800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.091871</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.690000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.236000</td>\n",
       "      <td>3.394400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.400000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.351000</td>\n",
       "      <td>2.405000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.003000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4559</th>\n",
       "      <td>4.175650</td>\n",
       "      <td>3.454649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.398382</td>\n",
       "      <td>3.241090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.406748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4560</th>\n",
       "      <td>3.853731</td>\n",
       "      <td>2.747142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.429148</td>\n",
       "      <td>2.719309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.511511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4561</th>\n",
       "      <td>4.294771</td>\n",
       "      <td>3.471226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.422154</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.351666</td>\n",
       "      <td>2.729456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.699324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4562</th>\n",
       "      <td>4.560376</td>\n",
       "      <td>3.896390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.872380</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.509342</td>\n",
       "      <td>3.059198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.908802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4563</th>\n",
       "      <td>4.045097</td>\n",
       "      <td>2.847185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.386643</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.032224</td>\n",
       "      <td>2.613357</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.863314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4564 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SpMax_L   J_Dz(e)  nHM  F01  F04  NssssC  nCb          C  nCp   nO   \n",
       "0     3.919000  2.690900  0.0  0.0  0.0     0.0  0.0  31.400000  2.0  0.0  \\\n",
       "1     4.170000  2.114400  0.0  0.0  0.0     0.0  0.0  30.800000  1.0  1.0   \n",
       "2     3.932000  3.251200  0.0  0.0  0.0     0.0  0.0  26.700000  2.0  4.0   \n",
       "3     3.000000  2.709800  0.0  0.0  0.0     0.0  0.0  20.000000  1.0  2.0   \n",
       "4     4.236000  3.394400  0.0  0.0  0.0     0.0  0.0  29.400000  2.0  4.0   \n",
       "...        ...       ...  ...  ...  ...     ...  ...        ...  ...  ...   \n",
       "4559  4.175650  3.454649  0.0  0.0  0.0     0.0  0.0  27.300000  2.0  2.0   \n",
       "4560  3.853731  2.747142  0.0  0.0  0.0     0.0  0.0  33.300000  0.0  0.0   \n",
       "4561  4.294771  3.471226  0.0  0.0  0.0     0.0  0.0  28.422154  2.0  2.0   \n",
       "4562  4.560376  3.896390  0.0  0.0  0.0     0.0  0.0  31.872380  2.0  3.0   \n",
       "4563  4.045097  2.847185  0.0  0.0  0.0     0.0  0.0  23.386643  1.0  1.0   \n",
       "\n",
       "      ...  C_026  F02_CN  nHDon   SpMax_B   Psi_i_A   nN     SM6_B  nArCOOR   \n",
       "0     ...    0.0     0.0    0.0  2.949000  1.591000  0.0  7.253000      0.0  \\\n",
       "1     ...    0.0     0.0    0.0  3.315000  1.967000  0.0  7.257000      0.0   \n",
       "2     ...    0.0     0.0    1.0  3.183760  2.417000  0.0  7.601000      0.0   \n",
       "3     ...    0.0     0.0    1.0  3.091871  5.000000  0.0  6.690000      0.0   \n",
       "4     ...    0.0     0.0    0.0  3.351000  2.405000  0.0  8.003000      0.0   \n",
       "...   ...    ...     ...    ...       ...       ...  ...       ...      ...   \n",
       "4559  ...    0.0     0.0    0.0  3.398382  3.241090  0.0  7.406748      0.0   \n",
       "4560  ...    0.0     0.0    1.0  3.429148  2.719309  0.0  7.511511      0.0   \n",
       "4561  ...    0.0     0.0    0.0  3.351666  2.729456  0.0  7.699324      0.0   \n",
       "4562  ...    0.0     0.0    0.0  3.509342  3.059198  0.0  7.908802      0.0   \n",
       "4563  ...    0.0     2.0    2.0  3.032224  2.613357  1.0  6.863314      0.0   \n",
       "\n",
       "       nX  Biodegradable_RB  \n",
       "0     0.0                 1  \n",
       "1     0.0                 1  \n",
       "2     0.0                 1  \n",
       "3     0.0                 1  \n",
       "4     0.0                 1  \n",
       "...   ...               ...  \n",
       "4559  0.0                 1  \n",
       "4560  0.0                 1  \n",
       "4561  0.0                 1  \n",
       "4562  0.0                 1  \n",
       "4563  0.0                 1  \n",
       "\n",
       "[4564 rows x 42 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binario = pd.get_dummies(dataSet, columns=['Biodegradable'], prefix=['Biodegradable']);\n",
    "\n",
    "dataSet = pd.concat([dataSet, binario['Biodegradable_RB']], axis=1)\n",
    "dataSet = dataSet.drop('Biodegradable', axis=1)\n",
    "dataSet['Biodegradable_RB'] = dataSet['Biodegradable_RB'].astype(int)\n",
    "\n",
    "\n",
    "dataSet\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e05a65a",
   "metadata": {},
   "source": [
    "### Scaling data... To see wich is the best scaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56529972",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, matthews_corrcoef, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler,StandardScaler\n",
    "\n",
    "# Método retirado do notebook: EC_TP04.ipynb -> 2022/2023\n",
    "# Este método imprime um conjunto de estatísticas sobre um determinado modelo treinado e as suas previsoes.\n",
    "def printClassResults(truth, preds):\n",
    "    print(\"The Accuracy is: %7.4f\" % accuracy_score(truth, preds))\n",
    "    print(\"The Precision is: %7.4f\" % precision_score(truth, preds))\n",
    "    print(\"The Recall is: %7.4f\" % recall_score(truth, preds))\n",
    "    print(\"The F1 score is: %7.4f\" % f1_score(truth, preds))\n",
    "    print(\"The Matthews correlation coefficient is: %7.4f\" % matthews_corrcoef(truth, preds))\n",
    "    #print()\n",
    "    #print(\"This is the Confusion Matrix\")\n",
    "    #print(pd.DataFrame(confusion_matrix(truth, preds)))\n",
    "\n",
    "\n",
    "scalers = {\n",
    "    'StandardScaler': StandardScaler(),\n",
    "    'RobustScaler': RobustScaler(),\n",
    "    'MinMaxScaler': MinMaxScaler()\n",
    "}\n",
    "\n",
    "def testScalers(scalers, model, results,Xtrain,Xtest,Ytrain,Ytest):\n",
    "\n",
    "    for scaler_name, scaler in scalers.items():\n",
    "        X_train_scaled = scaler.fit_transform(Xtrain)\n",
    "        X_test_scaled = scaler.transform(Xtest)\n",
    "        \n",
    "        model.fit(X_train_scaled, Ytrain)\n",
    "        \n",
    "        Ypred = model.predict(X_test_scaled)\n",
    "        \n",
    "        accuracy = accuracy_score(Ytest, Ypred)\n",
    "        \n",
    "        results[scaler_name] = accuracy\n",
    "\n",
    "        print(\"Scaler: \",scaler_name,\"\\n\");\n",
    "        printClassResults(Ytest,Ypred);\n",
    "        print()\n",
    "\n",
    "def scaleData(scaler,Xtrain,Xtest):\n",
    "    X_train_scaled = scaler.fit_transform(Xtrain)\n",
    "    X_test_scaled = scaler.transform(Xtest)\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63c2bb71",
   "metadata": {},
   "source": [
    "##### Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f142122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler:  StandardScaler \n",
      "\n",
      "The Accuracy is:  0.9608\n",
      "The Precision is:  0.9634\n",
      "The Recall is:  0.9914\n",
      "The F1 score is:  0.9772\n",
      "The Matthews correlation coefficient is:  0.8441\n",
      "\n",
      "Scaler:  RobustScaler \n",
      "\n",
      "The Accuracy is:  0.9575\n",
      "The Precision is:  0.9611\n",
      "The Recall is:  0.9898\n",
      "The F1 score is:  0.9753\n",
      "The Matthews correlation coefficient is:  0.8304\n",
      "\n",
      "Scaler:  MinMaxScaler \n",
      "\n",
      "The Accuracy is:  0.9416\n",
      "The Precision is:  0.9425\n",
      "The Recall is:  0.9914\n",
      "The F1 score is:  0.9663\n",
      "The Matthews correlation coefficient is:  0.7612\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Temos que X sao as features e o Y é a variavel de classificação\n",
    "X = dataSet.drop('Biodegradable_RB', axis=1)\n",
    "y = dataSet['Biodegradable_RB']\n",
    "\n",
    "# Faz-se a divisao entre teste e treino \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=22)\n",
    "\n",
    "results = {}\n",
    "\n",
    "testScalers(scalers,LogisticRegression(max_iter=1000,random_state=0),results,X_train,X_test,y_train,y_test);\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4988eceb",
   "metadata": {},
   "source": [
    "Tendo em conta os resultados para o Logistic Regression temos que o **Standart Scaler** obteve melhores resultados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99d48e2c",
   "metadata": {},
   "source": [
    "#### Decision Trees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58c3aaa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler:  StandardScaler \n",
      "\n",
      "The Accuracy is:  0.9662\n",
      "The Precision is:  0.9789\n",
      "The Recall is:  0.9812\n",
      "The F1 score is:  0.9800\n",
      "The Matthews correlation coefficient is:  0.8699\n",
      "\n",
      "Scaler:  RobustScaler \n",
      "\n",
      "The Accuracy is:  0.9575\n",
      "The Precision is:  0.9741\n",
      "The Recall is:  0.9757\n",
      "The F1 score is:  0.9749\n",
      "The Matthews correlation coefficient is:  0.8370\n",
      "\n",
      "Scaler:  MinMaxScaler \n",
      "\n",
      "The Accuracy is:  0.9542\n",
      "The Precision is:  0.9733\n",
      "The Recall is:  0.9725\n",
      "The F1 score is:  0.9729\n",
      "The Matthews correlation coefficient is:  0.8252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Temos que X sao as features e o Y é a variavel de classificação\n",
    "X = dataSet.drop('Biodegradable_RB', axis=1)\n",
    "y = dataSet['Biodegradable_RB']\n",
    "\n",
    "# Faz-se a divisao entre teste e treino \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=22)\n",
    "\n",
    "results = {}\n",
    "\n",
    "testScalers(scalers,DecisionTreeClassifier(),results,X_train,X_test,y_train,y_test);\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e10a4237",
   "metadata": {},
   "source": [
    "Tendo em conta os resultados para as Decision Trees temos que o **Robust Scaler** obteve melhores resultados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8cb0dc02",
   "metadata": {},
   "source": [
    "#### Random Forests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce11719f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler:  StandardScaler \n",
      "\n",
      "The Accuracy is:  0.9728\n",
      "The Precision is:  0.9813\n",
      "The Recall is:  0.9867\n",
      "The F1 score is:  0.9840\n",
      "The Matthews correlation coefficient is:  0.8948\n",
      "\n",
      "Scaler:  RobustScaler \n",
      "\n",
      "The Accuracy is:  0.9735\n",
      "The Precision is:  0.9805\n",
      "The Recall is:  0.9882\n",
      "The F1 score is:  0.9844\n",
      "The Matthews correlation coefficient is:  0.8970\n",
      "\n",
      "Scaler:  MinMaxScaler \n",
      "\n",
      "The Accuracy is:  0.9715\n",
      "The Precision is:  0.9782\n",
      "The Recall is:  0.9882\n",
      "The F1 score is:  0.9832\n",
      "The Matthews correlation coefficient is:  0.8888\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Temos que X sao as features e o Y é a variavel de classificação\n",
    "X = dataSet.drop('Biodegradable_RB', axis=1)\n",
    "y = dataSet['Biodegradable_RB']\n",
    "\n",
    "# Faz-se a divisao entre teste e treino \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=22)\n",
    "\n",
    "results = {}\n",
    "\n",
    "testScalers(scalers,RandomForestClassifier(),results,X_train,X_test,y_train,y_test);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f434990",
   "metadata": {},
   "source": [
    "Tendo em conta os resultados para o Random Forests temos que o **MinMaxScaler** obteve melhores resultados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "740b639e",
   "metadata": {},
   "source": [
    "####"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e323895",
   "metadata": {},
   "source": [
    "#### SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31dbd0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler:  StandardScaler \n",
      "\n",
      "The Accuracy is:  0.9688\n",
      "The Precision is:  0.9716\n",
      "The Recall is:  0.9922\n",
      "The F1 score is:  0.9817\n",
      "The Matthews correlation coefficient is:  0.8770\n",
      "\n",
      "Scaler:  RobustScaler \n",
      "\n",
      "The Accuracy is:  0.9608\n",
      "The Precision is:  0.9620\n",
      "The Recall is:  0.9929\n",
      "The F1 score is:  0.9772\n",
      "The Matthews correlation coefficient is:  0.8440\n",
      "\n",
      "Scaler:  MinMaxScaler \n",
      "\n",
      "The Accuracy is:  0.9502\n",
      "The Precision is:  0.9531\n",
      "The Recall is:  0.9898\n",
      "The F1 score is:  0.9711\n",
      "The Matthews correlation coefficient is:  0.7992\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Temos que X sao as features e o Y é a variavel de classificação\n",
    "X = dataSet.drop('Biodegradable_RB', axis=1)\n",
    "y = dataSet['Biodegradable_RB']\n",
    "\n",
    "# Faz-se a divisao entre teste e treino \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=22)\n",
    "\n",
    "results = {}\n",
    "\n",
    "testScalers(scalers,SVC(),results,X_train,X_test,y_train,y_test);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab397a8c",
   "metadata": {},
   "source": [
    "Tendo em conta os resultados para o SVM temos que o **Standart Scaler** obteve melhores resultados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d815a49",
   "metadata": {},
   "source": [
    "#### Tendo em conta que em todos os testes usando 4 modelos diferentes, o StandartScaler obteve os melhores resultados em 2 dos 4 testes, *a não ser que seja utilizado no final o modelo Decision Trees, ou Random Forests mas mesmo com estes modelos os valores do StandartScaler continuam bem positivos*, deve ser utilizado o método de scaling : **StandartScaler**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fdfc5e56",
   "metadata": {},
   "source": [
    "## Identificar e remover colunas irrelevantes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf53a534",
   "metadata": {},
   "source": [
    "#### Usar o Correlation selection method para remover variáveis irrelavantes:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "664159b1",
   "metadata": {},
   "source": [
    "Para encontrarmos as variaveis irrelevantes temos de procurar as variaveis que têm uma correlação perto de 0 pois perto de 1 significa que apoiam fortemente a feature alvo (Biodegradable) e perto de -1 rejeitam fortemente a feature alvo, daí as que têm uma correlacao com valor perto de 0 serem irrelevantes pois nem apoiam nem rejeitam a feature alvo nao trazendo assim vantagens suficientes para continuarem no dataSet.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1d6ab13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import f1_score, confusion_matrix,matthews_corrcoef, precision_score, recall_score\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8aa4f276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teste com * TODAS * as variáveis:\n",
      "Scaler:  StandartScaler \n",
      "\n",
      "The Accuracy is:  0.9728\n",
      "The Precision is:  0.9798\n",
      "The Recall is:  0.9882\n",
      "The F1 score is:  0.9840\n",
      "The Matthews correlation coefficient is:  0.8942\n",
      "\n",
      "Foram removidas 22 features de modo a diminuir a dimensionalidade dos dados\n",
      "\n",
      "\n",
      "Teste após * SEREM REMOVIDAS AS VARIAVEIS IRRELEVANTES *\n",
      "Scaler:  StandartScaler \n",
      "\n",
      "The Accuracy is:  0.9701\n",
      "The Precision is:  0.9738\n",
      "The Recall is:  0.9914\n",
      "The F1 score is:  0.9825\n",
      "The Matthews correlation coefficient is:  0.8826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Temos que X sao as features e o Y é a variavel de classificação\n",
    "X = dataSet.drop('Biodegradable_RB', axis=1)\n",
    "y = dataSet['Biodegradable_RB']\n",
    "\n",
    "#Escala-se a data a ser utilizada, com o StandartScaler (melhor dos testes)\n",
    "Xtrain_scaled, Xtest_scaled = scaleData(StandardScaler(),X_train,X_test)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=22)\n",
    "\n",
    "results = {}\n",
    "# Obter as stats antes da remocao das irrelevantes\n",
    "print(\"Teste com * TODAS * as variáveis:\")\n",
    "testScalers({'StandartScaler':StandardScaler()},RandomForestClassifier(),results,X_train,X_test,y_train,y_test);\n",
    "\n",
    "\n",
    "\n",
    "#REMOVER VARIÀVEIS IRRELEVANTES:\n",
    "\n",
    "#print(pd.DataFrame(Xtrain_scaled))\n",
    "N,M=Xtrain_scaled.shape\n",
    "N,M\n",
    "v=np.hstack((y_train.values.reshape((N,1)), Xtrain_scaled))\n",
    "#print(pd.DataFrame(v))\n",
    "corr_data = pd.DataFrame(np.corrcoef(v.T))\n",
    "first_column = corr_data.iloc[:, 0]\n",
    "#print(first_column);\n",
    "positive = True\n",
    "counter=1;\n",
    "\n",
    "selColIndexs = []\n",
    "\n",
    "while positive and counter<len(first_column):\n",
    "    \n",
    "    value = first_column.iloc[counter];\n",
    "\n",
    "    if(value>0 or value<-0.35):\n",
    "        selColIndexs.append(counter-1);\n",
    "    counter+=1\n",
    "        \n",
    "# indices (já sem a coluna adicionada da variavel alvo) com as features que nao foram removidas - ou seja as relevantes;\n",
    "selColIndexs.append(dataSet.shape[1]-1);\n",
    "\n",
    "#Apartir de agora este é o novo DataSet contendo apenas as colunas relevantes\n",
    "smallDataSet = dataSet.iloc[:,selColIndexs];\n",
    "\n",
    "# Temos que X sao as features e o Y é a variavel de classificação\n",
    "X = smallDataSet.drop('Biodegradable_RB', axis=1)\n",
    "y = smallDataSet['Biodegradable_RB']\n",
    "\n",
    "#Escala-se a data a ser utilizada, com o StandartScaler (melhor dos testes)\n",
    "Xtrain_scaled, Xtest_scaled = scaleData(StandardScaler(),X_train,X_test)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=22)\n",
    "\n",
    "#Numero de variaveis removidas de maneira a reduzir a dimensionalidade\n",
    "print(\"Foram removidas\",len(first_column) - len(selColIndexs),\"features de modo a diminuir a dimensionalidade dos dados\");\n",
    "\n",
    "\n",
    "print(\"\\n\\nTeste após * SEREM REMOVIDAS AS VARIAVEIS IRRELEVANTES *\");\n",
    "testScalers({'StandartScaler':StandardScaler()},RandomForestClassifier(),results,X_train,X_test,y_train,y_test);\n",
    "\n",
    "smallDataSet;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f54e872",
   "metadata": {},
   "source": [
    "Desta maneira acabámos por reduzir a dimensionalidade dos dados, eliminando cerca de 22 colunas irrelevantes e ainda acabámos por melhorar um pouco a accuracy de previsão usando uma RandomForest e escalando os dados com StandartScaler\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76834e3d",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "653fd9a0",
   "metadata": {},
   "source": [
    "\n",
    "# | --------------------------------------------------- |\n",
    "# | ---- EM PROGRESSO : A PARTIR DE AQUI ------|\n",
    "# V -------------------------------------------------- V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f0bf26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6f93f86",
   "metadata": {},
   "source": [
    "#### Using Stepwise Feature selection method :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c230f4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features selected are columns:  [ 1  3  5  7 10]\n"
     ]
    }
   ],
   "source": [
    "#ESTE PASSO COSTUMA DEMORAR CERCA DE 2 MIN A EXECUTAR !!\n",
    "\n",
    "# Vamos tentar descobrir quais as 5 variáveis mais relevantes usando o Stepwise Feature selection.\n",
    "\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "# Temos que X sao as features e o Y é a variavel de classificação\n",
    "X = smallDataSet.drop('Biodegradable_RB', axis=1)\n",
    "y =smallDataSet['Biodegradable_RB']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=22)\n",
    "\n",
    "Xtrain_scaled, Xtest_scaled = scaleData(StandardScaler(),X_train,X_test)\n",
    "\n",
    "N,M=Xtrain_scaled.shape\n",
    "\n",
    "#using RandomForest for sequential feature selection\n",
    "clf = RandomForestClassifier()\n",
    "sfs = SequentialFeatureSelector(clf, n_features_to_select=5)\n",
    "sfs.fit(Xtrain_scaled, y_train)\n",
    "\n",
    "#get the relevant columns\n",
    "features=sfs.get_support()\n",
    "Features_selected =np.arange(M)[features]\n",
    "print(\"The features selected are columns: \", Features_selected)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cdf6071e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teste com * TODAS * as variáveis - utilizando o StandartScaler:\n",
      "Scaler:  StandartScaler \n",
      "\n",
      "The Accuracy is:  0.9728\n",
      "The Precision is:  0.9761\n",
      "The Recall is:  0.9922\n",
      "The F1 score is:  0.9840\n",
      "The Matthews correlation coefficient is:  0.8933\n",
      "\n",
      "\n",
      "\n",
      " Teste com * APENAS AS VARIÀVEIS SELECIONADAS *  - utilizando o StandartScaler:\n",
      "Scaler:  StandartScaler \n",
      "\n",
      "The Accuracy is:  0.9482\n",
      "The Precision is:  0.9544\n",
      "The Recall is:  0.9859\n",
      "The F1 score is:  0.9699\n",
      "The Matthews correlation coefficient is:  0.7915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Teste com * TODAS * as variáveis - utilizando o StandartScaler:\")\n",
    "testScalers({'StandartScaler':StandardScaler()},RandomForestClassifier(),results,X_train,X_test,y_train,y_test);\n",
    "\n",
    "newXtrain =sfs.transform(Xtrain_scaled)\n",
    "newXtest = sfs.transform(Xtest_scaled)\n",
    "\n",
    "\n",
    "print(\"\\n\\n Teste com * APENAS AS VARIÀVEIS SELECIONADAS *  - utilizando o StandartScaler:\");\n",
    "testScalers({'StandartScaler':StandardScaler()},RandomForestClassifier(),results,newXtrain,newXtest,y_train,y_test);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "058a8758",
   "metadata": {},
   "source": [
    "#### Using PCA selection method :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59414573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teste com * TODAS * as variáveis - utilizando o StandartScaler:\n",
      "Scaler:  StandartScaler \n",
      "\n",
      "The Accuracy is:  0.9735\n",
      "The Precision is:  0.9813\n",
      "The Recall is:  0.9874\n",
      "The F1 score is:  0.9844\n",
      "The Matthews correlation coefficient is:  0.8972\n",
      "\n",
      "PC0 - Variance explained:  0.1943 - Total Variance:  0.1943\n",
      "PC1 - Variance explained:  0.1135 - Total Variance:  0.3078\n",
      "PC2 - Variance explained:  0.1019 - Total Variance:  0.4097\n",
      "PC3 - Variance explained:  0.0822 - Total Variance:  0.4920\n",
      "PC4 - Variance explained:  0.0700 - Total Variance:  0.5619\n",
      "PC5 - Variance explained:  0.0504 - Total Variance:  0.6123\n",
      "PC6 - Variance explained:  0.0351 - Total Variance:  0.6474\n",
      "PC7 - Variance explained:  0.0315 - Total Variance:  0.6789\n",
      "PC8 - Variance explained:  0.0305 - Total Variance:  0.7094\n",
      "PC9 - Variance explained:  0.0284 - Total Variance:  0.7378\n",
      "PC10 - Variance explained:  0.0261 - Total Variance:  0.7639\n",
      "PC11 - Variance explained:  0.0248 - Total Variance:  0.7886\n",
      "PC12 - Variance explained:  0.0237 - Total Variance:  0.8124\n",
      "PC13 - Variance explained:  0.0207 - Total Variance:  0.8331\n",
      "PC14 - Variance explained:  0.0190 - Total Variance:  0.8520\n",
      "PC15 - Variance explained:  0.0163 - Total Variance:  0.8684\n",
      "PC16 - Variance explained:  0.0156 - Total Variance:  0.8840\n",
      "PC17 - Variance explained:  0.0140 - Total Variance:  0.8980\n",
      "PC18 - Variance explained:  0.0110 - Total Variance:  0.9090\n",
      "PC19 - Variance explained:  0.0102 - Total Variance:  0.9192\n",
      "\n",
      "(1507, 20)\n",
      "\n",
      "\n",
      " Teste com * APENAS AS VARIÀVEIS SELECIONADAS *  - utilizando o StandartScaler:\n",
      "Scaler:  StandartScaler \n",
      "\n",
      "The Accuracy is:  0.9648\n",
      "The Precision is:  0.9700\n",
      "The Recall is:  0.9890\n",
      "The F1 score is:  0.9794\n",
      "The Matthews correlation coefficient is:  0.8612\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Temos que X sao as features e o Y é a variavel de classificação\n",
    "X = dataSet.drop('Biodegradable_RB', axis=1)\n",
    "y = dataSet['Biodegradable_RB']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=22)\n",
    "\n",
    "Xtrain_scaled, Xtest_scaled = scaleData(StandardScaler(),X_train,X_test)\n",
    "\n",
    "print(\"Teste com * TODAS * as variáveis - utilizando o StandartScaler:\")\n",
    "testScalers({'StandartScaler':StandardScaler()},RandomForestClassifier(),results,Xtrain_scaled,Xtest_scaled,y_train,y_test);\n",
    "\n",
    "#utilizamos 20 PCs pois após várias tentaivas é o valor que nos permite obter uma Total variance de pelo menos 90% \n",
    "pca = PCA(n_components=20) \n",
    "pca.fit(Xtrain_scaled)\n",
    "tve=0 #total variance explained\n",
    "for i, ve in enumerate(pca.explained_variance_ratio_):\n",
    "    tve+=ve\n",
    "    print(\"PC%d - Variance explained: %7.4f - Total Variance: %7.4f\" % (i, ve, tve) )\n",
    "print()\n",
    "#print(\"Actual Eigenvalues:\", pca.singular_values_)\n",
    "\n",
    "newX_train=pca.transform(Xtrain_scaled)\n",
    "newX_test=pca.transform(Xtest_scaled)\n",
    "\n",
    "print(newX_test.shape);\n",
    "\n",
    "print(\"\\n\\n Teste com * APENAS AS VARIÀVEIS SELECIONADAS *  - utilizando o StandartScaler:\");\n",
    "testScalers({'StandartScaler':StandardScaler()},RandomForestClassifier(),results,newX_train,newX_test,y_train,y_test);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "032381c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Temos que X sao as features e o Y é a variavel de classificação\n",
    "# X = dataSet.drop('Biodegradable_RB', axis=1)\n",
    "# y = dataSet['Biodegradable_RB']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=22)\n",
    "\n",
    "# Xtrain_scaled, Xtest_scaled = scaleData(StandardScaler(),X_train,X_test)\n",
    "# print(\"Teste com * TODAS * as variáveis - utilizando o StandartScaler:\")\n",
    "# testScalers({'StandartScaler':StandardScaler()},RandomForestClassifier(),results,Xtrain_scaled,Xtest_scaled,y_train,y_test);\n",
    "\n",
    "\n",
    "# X_pca = pca.fit_transform(Xtrain_scaled)\n",
    "\n",
    "# loadings = pca.components_\n",
    "\n",
    "# feature_count = {}\n",
    "\n",
    "# # Esta parte do código foi obtida com ajuda da ferramenta ChatGPT\n",
    "# for i, component in enumerate(loadings):\n",
    "#     feature_indices = np.argsort(np.abs(component))[::-1] \n",
    "#     contributing_features = feature_indices[:10]  \n",
    "#     for feature_index in contributing_features:\n",
    "#         feature_name = X.columns[feature_index]\n",
    "#         if feature_name in feature_count:\n",
    "#             feature_count[feature_name] += 1\n",
    "#         else:\n",
    "#             feature_count[feature_name] = 1\n",
    "\n",
    "# sorted_features = sorted(feature_count.items(), key=lambda x: x[1], reverse=True)[:20]\n",
    "\n",
    "\n",
    "# selected_feature_names = [feature for feature, count in sorted_features]\n",
    "\n",
    "# filtered_dataset = dataSet.loc[:, selected_feature_names]\n",
    "# filtered_dataset\n",
    "\n",
    "# # Temos que X sao as features e o Y é a variavel de classificação\n",
    "# X = filtered_dataset\n",
    "# y = dataSet['Biodegradable_RB']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=22)\n",
    "\n",
    "# Xtrain_scaled, Xtest_scaled = scaleData(StandardScaler(),X_train,X_test)\n",
    "\n",
    "\n",
    "# print(\"\\n\\n Teste com * APENAS AS VARIÀVEIS SELECIONADAS *  - utilizando o StandartScaler:\");\n",
    "# testScalers({'StandartScaler':StandardScaler()},RandomForestClassifier(),results,newX_train,newX_test,y_train,y_test);\n",
    "\n",
    "# print(\"Features selecionadas:\",selected_feature_names);\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54feb2b5",
   "metadata": {},
   "source": [
    "Tendo em conta os resultados, os métodos que mais afetam a dimensionalidade são a Correlation e a SFS mas o que melhores resultados apresenta é o PCA com um accuracy: 0.9615 e um F1 score: 0.9775 face aos 0.9721 e 0.9890 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
